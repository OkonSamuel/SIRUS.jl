var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Types","page":"API","title":"Types","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"StableRulesClassifier\nStableRulesRegressor\nStableForestClassifier\nStableForestRegressor","category":"page"},{"location":"api/#SIRUS.StableRulesClassifier","page":"API","title":"SIRUS.StableRulesClassifier","text":"StableRulesClassifier\n\nA model type for constructing a stable rules classifier, based on SIRUS.jl, and implementing the MLJ model interface.\n\nFrom MLJ, the type can be imported using\n\nStableRulesClassifier = @load StableRulesClassifier pkg=SIRUS\n\nDo model = StableRulesClassifier() to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in StableRulesClassifier(rng=...).\n\nStableRulesClassifier implements the explainable rule-based model based on a random forest.\n\nTraining data\n\nIn MLJ or MLJBase, bind an instance model to data with\n\nmach = machine(model, X, y)\n\nwhere\n\nX: any table of input features (eg, a DataFrame) whose columns each have one of the following element scitypes: Continuous, Count, or <:OrderedFactor; check column scitypes with schema(X)\ny: the target, which can be any AbstractVector whose element scitype is <:OrderedFactor or <:Multiclass; check the scitype with scitype(y)\n\nTrain the machine with fit!(mach, rows=...).\n\nHyperparameters\n\nrng::AbstractRNG=default_rng(): Random number generator.   Using a StableRNG from StableRNGs.jl is advised.\npartial_sampling::Float64=0.7:   Ratio of samples to use in each subset of the data.   The default should be fine for most cases.\nn_trees::Int=1000:   The number of trees to use.   It is advisable to use at least thousand trees to for a better rule selection, and   in turn better predictive performance.\nmax_depth::Int=2:   The depth of the tree.   A lower depth decreases model complexity and can therefore improve accuracy when the sample size is small (reduce overfitting).\nq::Int=10: Number of cutpoints to use per feature.   The default value should be fine for most situations.\nmin_data_in_leaf::Int=5: Minimum number of data points per leaf.\nmax_rules::Int=10:   This is the most important hyperparameter.   In general, the more rules, the more accurate the model.   However, more rules will also decrease model interpretability.   So, it is important to find a good balance here.   In most cases, 10 to 40 rules should provide reasonable accuracy while remaining interpretable.\nlambda::Float64=1.0:   The weights of the final rules are determined via a regularized regression over each rule as a binary feature.   This hyperparameter specifies the strength of the ridge (L2) regularizer.\n\n\n\n\n\n","category":"type"},{"location":"api/#SIRUS.StableRulesRegressor","page":"API","title":"SIRUS.StableRulesRegressor","text":"StableRulesRegressor\n\nA model type for constructing a stable rules regressor, based on SIRUS.jl, and implementing the MLJ model interface.\n\nFrom MLJ, the type can be imported using\n\nStableRulesRegressor = @load StableRulesRegressor pkg=SIRUS\n\nDo model = StableRulesRegressor() to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in StableRulesRegressor(rng=...).\n\nStableRulesRegressor implements the explainable rule-based regression model based on a random forest.\n\nTraining data\n\nIn MLJ or MLJBase, bind an instance model to data with\n\nmach = machine(model, X, y)\n\nwhere\n\nX: any table of input features (eg, a DataFrame) whose columns each have one of the following element scitypes: Continuous, Count, or <:OrderedFactor; check column scitypes with schema(X)\ny: the target, which can be any AbstractVector whose element scitype is <:OrderedFactor or <:Multiclass; check the scitype with scitype(y)\n\nTrain the machine with fit!(mach, rows=...).\n\nHyperparameters\n\nrng::AbstractRNG=default_rng(): Random number generator.   Using a StableRNG from StableRNGs.jl is advised.\npartial_sampling::Float64=0.7:   Ratio of samples to use in each subset of the data.   The default should be fine for most cases.\nn_trees::Int=1000:   The number of trees to use.   It is advisable to use at least thousand trees to for a better rule selection, and   in turn better predictive performance.\nmax_depth::Int=2:   The depth of the tree.   A lower depth decreases model complexity and can therefore improve accuracy when the sample size is small (reduce overfitting).\nq::Int=10: Number of cutpoints to use per feature.   The default value should be fine for most situations.\nmin_data_in_leaf::Int=5: Minimum number of data points per leaf.\nmax_rules::Int=10:   This is the most important hyperparameter.   In general, the more rules, the more accurate the model.   However, more rules will also decrease model interpretability.   So, it is important to find a good balance here.   In most cases, 10 to 40 rules should provide reasonable accuracy while remaining interpretable.\nlambda::Float64=1.0:   The weights of the final rules are determined via a regularized regression over each rule as a binary feature.   This hyperparameter specifies the strength of the ridge (L2) regularizer.\n\n\n\n\n\n","category":"type"},{"location":"api/#SIRUS.StableForestClassifier","page":"API","title":"SIRUS.StableForestClassifier","text":"StableForestClassifier\n\nA model type for constructing a stable forest classifier, based on SIRUS.jl, and implementing the MLJ model interface.\n\nFrom MLJ, the type can be imported using\n\nStableForestClassifier = @load StableForestClassifier pkg=SIRUS\n\nDo model = StableForestClassifier() to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in StableForestClassifier(rng=...).\n\nStableForestClassifier implements the random forest classifier with a stabilized forest structure (Bénard et al., 2021). This stabilization increases stability when extracting rules. The impact on the predictive accuracy compared to standard random forests should be relatively small.\n\nnote: Note\nJust like normal random forests, this model is not easily explainable. If you are interested in an explainable model, use the StableRulesClassifier or StableRulesRegressor.\n\nTraining data\n\nIn MLJ or MLJBase, bind an instance model to data with\n\nmach = machine(model, X, y)\n\nwhere\n\nX: any table of input features (eg, a DataFrame) whose columns each have one of the following element scitypes: Continuous, Count, or <:OrderedFactor; check column scitypes with schema(X)\ny: the target, which can be any AbstractVector whose element scitype is <:OrderedFactor or <:Multiclass; check the scitype with scitype(y)\n\nTrain the machine with fit!(mach, rows=...).\n\nHyperparameters\n\nrng::AbstractRNG=default_rng(): Random number generator.   Using a StableRNG from StableRNGs.jl is advised.\npartial_sampling::Float64=0.7:   Ratio of samples to use in each subset of the data.   The default should be fine for most cases.\nn_trees::Int=1000:   The number of trees to use.   It is advisable to use at least thousand trees to for a better rule selection, and   in turn better predictive performance.\nmax_depth::Int=2:   The depth of the tree.   A lower depth decreases model complexity and can therefore improve accuracy when the sample size is small (reduce overfitting).\nq::Int=10: Number of cutpoints to use per feature.   The default value should be fine for most situations.\nmin_data_in_leaf::Int=5: Minimum number of data points per leaf.\n\n\n\n\n\n","category":"type"},{"location":"api/#SIRUS.StableForestRegressor","page":"API","title":"SIRUS.StableForestRegressor","text":"StableForestRegressor\n\nA model type for constructing a stable forest regressor, based on SIRUS.jl, and implementing the MLJ model interface.\n\nFrom MLJ, the type can be imported using\n\nStableForestRegressor = @load StableForestRegressor pkg=SIRUS\n\nDo model = StableForestRegressor() to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in StableForestRegressor(rng=...).\n\nStableForestRegressor implements the random forest regressor with a stabilized forest structure (Bénard et al., 2021).\n\nTraining data\n\nIn MLJ or MLJBase, bind an instance model to data with\n\nmach = machine(model, X, y)\n\nwhere\n\nX: any table of input features (eg, a DataFrame) whose columns each have one of the following element scitypes: Continuous, Count, or <:OrderedFactor; check column scitypes with schema(X)\ny: the target, which can be any AbstractVector whose element scitype is <:OrderedFactor or <:Multiclass; check the scitype with scitype(y)\n\nTrain the machine with fit!(mach, rows=...).\n\nHyperparameters\n\nrng::AbstractRNG=default_rng(): Random number generator.   Using a StableRNG from StableRNGs.jl is advised.\npartial_sampling::Float64=0.7:   Ratio of samples to use in each subset of the data.   The default should be fine for most cases.\nn_trees::Int=1000:   The number of trees to use.   It is advisable to use at least thousand trees to for a better rule selection, and   in turn better predictive performance.\nmax_depth::Int=2:   The depth of the tree.   A lower depth decreases model complexity and can therefore improve accuracy when the sample size is small (reduce overfitting).\nq::Int=10: Number of cutpoints to use per feature.   The default value should be fine for most situations.\nmin_data_in_leaf::Int=5: Minimum number of data points per leaf.\n\n\n\n\n\n","category":"type"},{"location":"api/#Methods","page":"API","title":"Methods","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"feature_names\ndirections\nvalues(::SIRUS.Rule)\nsatisfies\nCutpoints\ncutpoints","category":"page"},{"location":"api/#SIRUS.feature_names","page":"API","title":"SIRUS.feature_names","text":"feature_names(rule::Rule) -> Vector{String}\n\nReturn a vector of feature names; one for each clause in rule.\n\n\n\n\n\n","category":"function"},{"location":"api/#SIRUS.directions","page":"API","title":"SIRUS.directions","text":"directions(rule::Rule) -> Vector{Symbol}\n\nReturn a vector of split directions; one for each clause in rule.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.values-Tuple{SIRUS.Rule}","page":"API","title":"Base.values","text":"values(rule::Rule) -> Vector{Float64}\n\nReturn a vector split values; one for each clause in rule.\n\n\n\n\n\n","category":"method"},{"location":"api/#SIRUS.satisfies","page":"API","title":"SIRUS.satisfies","text":"satisfies(row::AbstractVector, rule::Rule) -> Bool\n\nReturn whether data row satisfies rule.\n\n\n\n\n\n","category":"function"},{"location":"api/#SIRUS.EmpiricalQuantiles.Cutpoints","page":"API","title":"SIRUS.EmpiricalQuantiles.Cutpoints","text":"Set of possible cutpoints, that is, empirical quantiles.\n\n\n\n\n\n","category":"type"},{"location":"api/#SIRUS.EmpiricalQuantiles.cutpoints","page":"API","title":"SIRUS.EmpiricalQuantiles.cutpoints","text":"Return a vector of q cutpoints taken from the empirical distribution from data V.\n\n\n\n\n\nReturn a vector of vectors containing\n\none inner vector for each feature in the dataset and\ninner vectors containing the unique cutpoints, that is, length(V[i]) ≤ q for all i in V.\n\nUsing unique here to avoid checking splits twice.\n\n\n\n\n\n","category":"function"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<style>\n    table {\n        display: table !important;\n        margin: 2rem auto !important;\n        border-top: 2pt solid rgba(0,0,0,0.2);\n        border-bottom: 2pt solid rgba(0,0,0,0.2);\n    }\n\n    pre, div {\n        margin-top: 1.4rem !important;\n        margin-bottom: 1.4rem !important;\n    }\n\n    .code-output {\n        padding: 0.7rem 0.5rem !important;\n    }\n\n    .admonition-body {\n        padding: 0em 1.25em !important;\n    }\n</style>\n\n<!-- PlutoStaticHTML.Begin -->\n<!--\n    # This information is used for caching.\n    [PlutoStaticHTML.State]\n    input_sha = \"0ee3ca2d07e8724cb035035a128793a144f32d89a7095505b6e2ebbb9a82c03e\"\n    julia_version = \"1.9.1\"\n-->\n\n\n\n\n\n\n\n<div class=\"markdown\"><p>This page will provide an overview of the algorithm and describe how it works and how it can be used. To do this, let's start by briefly describing random forests.</p></div>\n\n","category":"page"},{"location":"binary-classification/#Random-forests","page":"Simple Binary Classification","title":"Random forests","text":"","category":"section"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<div class=\"markdown\">\n<p>Random forests are known to produce accurate predictions especially in settings where the number of features <code>p</code> is close to or higher than the number of observations <code>n</code> (Biau &amp; Scornet, <a href=\"https://doi.org/10.1007/s11749-016-0481-7\">2016</a>). Let's start by explaining the building blocks of random forests: decision trees. As an example, we take Haberman's Survival Data Set (see the <em>Appendix</em> below for more code details):</p></div>\n\n<pre class='language-julia'><code class='language-julia'>data = _haberman()</code></pre>\n<table><tbody><tr><th></th><th>age</th><th>year</th><th>nodes</th><th>survival</th></tr><tr><td>1</td><td>30.0</td><td>1964.0</td><td>1.0</td><td>1</td></tr><tr><td>2</td><td>30.0</td><td>1962.0</td><td>3.0</td><td>1</td></tr><tr><td>3</td><td>30.0</td><td>1965.0</td><td>0.0</td><td>1</td></tr><tr><td>4</td><td>31.0</td><td>1959.0</td><td>2.0</td><td>1</td></tr><tr><td>5</td><td>31.0</td><td>1965.0</td><td>4.0</td><td>1</td></tr><tr><td>6</td><td>33.0</td><td>1958.0</td><td>10.0</td><td>1</td></tr><tr><td>7</td><td>33.0</td><td>1960.0</td><td>0.0</td><td>1</td></tr><tr><td>8</td><td>34.0</td><td>1959.0</td><td>0.0</td><td>0</td></tr><tr><td>9</td><td>34.0</td><td>1966.0</td><td>9.0</td><td>0</td></tr><tr><td>10</td><td>34.0</td><td>1958.0</td><td>30.0</td><td>1</td></tr><tr><td>...</td></tr><tr><td>306</td><td>83.0</td><td>1958.0</td><td>2.0</td><td>0</td></tr></tbody></table>\n\n<pre class='language-julia'><code class='language-julia'>X = data[:, Not(:survival)];</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>y = data.survival;</code></pre>\n\n\n\n<div class=\"markdown\"><p>This dataset contains observations from a study with patients who had breast cancer. The <code>survival</code> column contains a <code>0</code> if a patient has died within 5 years and <code>1</code> if the patient has survived for at least 5 years. The aim is to predict survival based on the <code>age</code>, the <code>year</code> in which the operation was conducted and the number of detected auxillary <code>nodes</code>.</p></div>\n\n\n<div class=\"markdown\"><p>Via <a href=\"https://github.com/alan-turing-institute/MLJ.jl\"><code>MLJ.jl</code></a>, we can fit multiple decision trees on this dataset:</p></div>\n\n<pre class='language-julia'><code class='language-julia'>tree_evaluations = let\n    model = DecisionTreeClassifier(; max_depth=2, rng=_rng())\n    _evaluate(model, X, y)\nend;</code></pre>\n\n\n\n<div class=\"markdown\"><p>This has fitted various trees to various subsets of the dataset via cross-validation. Here, I've set <code>max_depth=2</code> to simplify the fitted trees which makes the tree more easily explainable. Also, for our small dataset, this forces the model to remain simple so it likely reduces overfitting. Let's look at the first tree:</p></div>\n\n<pre class='language-julia'><code class='language-julia'>let\n    tree = tree_evaluations.fitted_params_per_fold[1].raw_tree\n    _io2text() do io\n        DecisionTree.print_tree(io, tree; feature_names=names(data))\n    end\nend</code></pre>\n<pre class=\"code-output documenter-example-output\" id=\"var-hash212960\">Feature 3: \"nodes\" &lt; 2.5 ?\n├─ Feature 1: \"age\" &lt; 79.5 ?\n    ├─ 2 : 151/178\n    └─ 1 : 1/1\n└─ Feature 1: \"age\" &lt; 43.5 ?\n    ├─ 2 : 16/20\n    └─ 1 : 42/76\n</pre>\n\n\n<div class=\"markdown\"><p>What this shows is that the first tree decided that the <code>nodes</code> feature is the most helpful in deciding who will survive for 5 more years. Next, if the <code>nodes</code> feature is below 2.5, then <code>age</code> will be selected on. If <code>age &lt; 79.5</code>, then the model will predict the second class and if <code>age ≥ 79.5</code> it will predict the first class. Similarly for <code>age &lt; 43.5</code>. Now, let's see what happens for a slight change in the data. In other words, let's see how the fitted model for the second split looks:</p></div>\n\n<pre class='language-julia'><code class='language-julia'>let\n    tree = tree_evaluations.fitted_params_per_fold[2].raw_tree\n    _io2text() do io\n        DecisionTree.print_tree(io, tree; feature_names=names(data))\n    end\nend</code></pre>\n<pre class=\"code-output documenter-example-output\" id=\"var-hash152761\">Feature 3: \"nodes\" &lt; 2.5 ?\n├─ Feature 1: \"age\" &lt; 77.0 ?\n    ├─ 2 : 147/175\n    └─ 1 : 2/2\n└─ Feature 1: \"age\" &lt; 43.5 ?\n    ├─ 2 : 18/21\n    └─ 1 : 41/77\n</pre>\n\n\n<div class=\"markdown\"><p>This shows that the features and the values for the splitpoints are not the same for both trees. This is called stability. Or in this case, a decision tree is considered to be unstable. This instability is problematic in situations where real-world decisions are based on the outcome of the model. Imagine using this model for the selecting which students are allowed to enter some university. If the model is updated every year with the data from the last year, then the selection criteria would vary wildly per year. This instability also causes accuracy to fluctuate wildly. Intuitively, this makes sense: if the model changes wildly for small data changes, then model accuracy also changes wildly. This intuitively also implies that the model is more likely to overfit. This is why random forests were introduced. Basically, random forests fit a large number of trees and average their predictions to come to a more accurate prediction. The individual trees are obtained by restricting the observations and the features that the trees are allowed to use. For the restriction on the observations, the trees are only allowed to see <code>partial_sampling * n</code> observations. In practise, <code>partial_sampling</code> is often 0.7. The restriction on the features is defined in such a way that it guarantees that not every tree will take the same split at the root of the tree. This makes the trees less correlated (James et al., <a href=\"https://doi.org/10.1007/978-1-0716-1418-1\">2021</a>; Section 8.2.2) and, hence, more accurate.</p><p>Unfortunately, these random forests are hard to interpret. To interpret the model, individuals would need to interpret hundreds to thousands of trees containing multiple levels. Alternatively, methods have been created to visualize these uninterpretable models (for example, see Molnar (<a href=\"https://christophm.github.io/interpretable-ml-book/\">2022</a>); Chapters 6, 7 and 8). The most promising one of these methods are Shapley values and SHAP. These methods show which features have the highest influence on the prediction. See my blog post on <a href=\"https://huijzer.xyz/posts/shapley/\">Random forests and Shapley values</a> for more information. Knowing which features have the highest influence is nice, but they do not state exactly what feature is used and at what cutoff. Again, this is not good enough for selecting students into universities. For example, what if the government decides to ask for details about the selection? The only answer that you can give is that some features are used for selection more than others and that they are on average used in a certain direction. If the government asks for biases in the model, then these are impossible to report. In practice, the decision is still a black-box. SIRUS solves this by extracting easily interpretable rules from the random forests.</p></div>\n\n","category":"page"},{"location":"binary-classification/#Rule-based-models","page":"Simple Binary Classification","title":"Rule-based models","text":"","category":"section"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<div class=\"markdown\">\n<p>Rule-based models promise much greater interpretability than random forests. Instead of returning a large number of trees, rule-based models return a set of rules. Each rule can be interpreted on its own and the final model aggregates these rules by summing the prediction of each rules. For example, one rule can be:</p><blockquote><p>if <code>nodes &lt; 4.5</code> then chance of survival is 0.6 and if <code>nodes ≥ 4.5</code> then chance of survival is 0.4.</p></blockquote><p>Note that these rules can be extracted quite easily from the decision trees. For splits on the second level of the tree, the rule could look like:</p><blockquote><p>if <code>nodes &lt; 4.5</code> and <code>age &lt; 38.5</code> then chance of survival is 0.8 and otherwise the chance of survival is 0.4.</p></blockquote><p>When applying this extracting of rules to a random forest, there will be thousands of rules. Next, via some heuristic, the most important rules can be localized and these rules then result in the final model. See, for example, RuleFit (Friedman &amp; Popescu, <a href=\"https://www.jstor.org/stable/30245114\">2008</a>). The problem with this approach is that they are fitted on the unstable decision trees that were shown above. As an example, on time the tree splits on <code>age &lt; 43.5</code> and another time on <code>age &lt; 44.5</code>.</p></div>\n\n","category":"page"},{"location":"binary-classification/#Tree-stabilization","page":"Simple Binary Classification","title":"Tree stabilization","text":"","category":"section"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<div class=\"markdown\">\n<p>In the papers which introduce SIRUS, Bénard et al. (<a href=\"https://doi.org/10.1214/20-EJS1792\">2021a</a>, <a href=\"https://proceedings.mlr.press/v130/benard21a.html\">2021b</a>) proof that their algorithm is stable and that the other algorithms are not. They achieve their stability by restricting the location at which the splitpoints can be chosen. To see how this works, let's look at the <code>age</code> feature on its own.</p></div>\n\n<pre class='language-julia'><code class='language-julia'>nodes = sort(data.age);</code></pre>\n\n\n\n\n\n\n<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAyAAAABkCAIAAADxM8PYAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3deVzUdf4H8PdnZmC4bxAQFJHwvkE0FXXpsFJz21p31WWtzKOsLFPTrMXKMo/sttXKDtNM2zZlFRU88EZFhLxQFOW+YWaAmYGZ7++PceF7fGZX+03C5uv5Rw/nw3tmPt/v93O8v9/5fL8xQRAIAAAAABxH1dYVAAAAAPitQYIFAAAA4GBIsAAAAAAcDAkWAAAAgIMhwQIAAABwMCRYAAAAAA6GBAsAAADAwZBgAQAAADgYEiwAAAAAB0OCBQAAAOBgSLAAAAAAHAwJFgAAAICDIcECAAAAcDAkWAAAAAAOprml6Pfeey8rKysiIuLXqQwAAABAu5Ofn9+/f/85c+bc/Ftu7QpWVlZWfn7+rVUK/sfp9Xqr1drWtQBoR8xmc2NjY1vXAqB90el0giC0dS1+Lfn5+VlZWbf0llu7ghUREREREZGUlHRL74L/acXFxUFBQRrNrTUVgN8wg8FgNpv9/PzauiIA7UhhYWFoaKhK9dtcevQLMp/f5o4AAAAAaENIsAAAAAAcDAkWAAAAgIMhwQIAAABwMCRYAAAAAA6GBAsAAADAwZBgAQAAADgYEiwAAAAAB0OCBQAAAOBgSLAAAAAAHAwJFgAAAICDIcECAAAAcDAkWAAAAAAOhgQLAAAAwME0bV0Bub2Xq2ZuOVOkM6oZ3RXo8cPU2AhfV2VYmc44+58/ZxbUNVuFHsGe747v2bOD5//ne5N2X/wxp7TcYA73dpk+tPO0uE7csAGr0s8U1wmMSKAgD+eyJfdzw9IuVS7ZnZtXWe+p1YyI9Ht/Qi83Z86uvlBmmLv97M8leo2K9e/o/dEjvUO8XJRhx6/WJKw92tBkFQRyUrMlD0QvHH2XMux6ZUPkO3stVoEYkcD6BHllL4jnVi/6rX151QYrkYqoX4hP5twR3LC39lz66Eh+db3Jzdlp9F0B308ZpFZzwu5ZczjtcjURESMV0dE5QweHBSjDknZceD3tkkBEREzFVo3t8cLIrsqw5NzK8euOCgKRQIzR76L8U2ferQzTmUyd3thbZ2wmgRhR/F0B+2cO5W5FwKs7qxotRAIR83dVV77xADds1KdH0y9VCoyIyNtFU/bqA1otb2M/PbL3cpUgEDFijLY9NXRsNGdjvzlZ8MT3Z5otAhFpGL03vtcz8ZHKsIzCyqGrj1mZQAIRUUKUX+qsYcowg4G8l/zLahVsW+Hn4lS1lN/wBq46eKak1nZku/p55C4azQ0LfjW1rMFITCCBMRX9/Hx8zzAvZdjDX2VszykTBEaMGAlfPzZwSlxHZdjrqblJO3Nt28AYPdIzbOsTA5Rh2QWVA987amECCSoiGtLJ++jz/IbX4W+7yg1mYsQE6hfqfXouvxn7Lk6pbWwiRkTMWSOYlo3jhv1xQ+bWM0WClRGzujtrLrycEObFObSv7jr31p4rVkEgIrWKtkwZ+Pt+nI09lF97/6dHG5stAglOKvb2Q73mjuyiDCuqbuzyzr6mZisxgQQa0sn36PPDudULSdpdpjcLTGDEugW4nX/5d9ywnu/sO19hIIGIkaeTuvxvD7pwhgp6LeXi8v2Xzc1WRizIXZvx4rBwbzdl2Ivbzr6XflUgIkFgRMvHd3tpZLQy7FxZXfzHx2oazYKVXDSapeN6vDA8QhlmMJsj39xf2WASiNTEHu4b8kPiIO5WrNyf9+2polKDKdRT+5fY8DkjOLuOiF7cdm7dsWuN5maNhvUN9j4ye4SGN1PN3vrzp8fyLYJAxFzUdHBOfEwopxnXNDatzyg4VVgrCBQT7jM1NtzPzUkZVlRrHLnmSEFto8UqeGo1yx7qOWMoZxawWunlHed2nC+vbjB38nF7Ib7rxAEh3K344ODVr04UFOtNwR7aPw8Inf+7KG7Y2VL9t5lFF8r1QR7aUV39/9g/VMUYp3p1xvUZBdklOndndVwn38SYMDdnznCsMzavP3H9ZEFds1UY2NH78cHhAe7OyrAmi/XbzKLDV6urG5p6h3j+NSY80p/TTto5g6n5yxMFJwpqjc3WAR29H48N7+DJG7XbDhME4eajk5KSWv77a3ht58U3UnPFJYyxlOlx90UHigtPFNYN++BQk8XaUqJi9NWkgVMGcgbE/8pqpR7L9+VWGMSF93UL3DV9iCzSaV5ys1W+u+reus9LOhUv2nH+7bTL4hIvF03ugtEdpMnTljMlf/rmpPjznNRs/9PD7o7wFYetOnD1pW0/y750SLjf0TmSmXh3XtX9a46QtHZqxppXjpW9V/XSdtkxV6tUzSsekoUNWp2eWVgnLnF1Ule9fr+rtFe7L9zZYG6WvXeFYryOe/dwRlENSes3uqv/3qclydNzW7M/PHpN9mluWqf6t8aIS65U6LouS5d9mouTunHZg7L3srnbSUFYJZ+JXef/yyhqTkREjPIWjIwMlIzX7otSGkxNsvc+O7TzB4/2FZf8+ZtT32UVyyryQM+AHU9KWtTKA7nztl2U10SjanhHciwulxruWrlPdmQZkVWxFZr5yRaLJI4xsq6Uh6nmJgskb8bfJA6e0q+DuMR30a5ak1kW9tiAjt9PGSguGbjy4OmSWlmYj4tLzdJ7xSXrj159Yqu8GTurmGmFpH3qTCbvRbtlYXaacbJ87GJkWDLO3V1S5vdaSk297JCx/TOGjoz2Fxf1WX7g5zKdLGza3RHr/tBbXLR8X+6Cf12U7bxhXX0PPS1JnnZdLBuzNkNWYWe12rRc0j5NJnJZJG+f3I3VzNsua57EWMnie4J9JENKv5Xp2aV10uqx/bPuHhnlJy7qtnx/bple9hUjIv3Tn5F0xk2niidtzJT2Mja6a8DepyXN+Eq1oevS/bIwbxd17VL5mczAd9NPF0mGlCGdfY8+J887I99KvVrVKC5RM6p88wEfF0mS1fnNtOs1DbL3/v2xAdOHhIlLcivqE9YcKawztpSEernsnTW0W5CHOCw9v3rkh4dlnzame9DOp+LEJcZma9RbaUWiTyOiPw0I3TRFnlAO+/DwkfxqcUm/UK+suSNlYd+cKnxy8xnxXDame9A/H4/VaiQ/Lh2+Wv3QZxl1xtaW3CvYc++soUEekqknv7ph9Jqj+dWtuyXIQ5s6c0ifEMk4pjc1j1l7XFw9Vyf194mDxvaUjAC/QGFhYWhoqEp1O34ZK6ozjv7kyKXK+pYSf3fnlKfiYsJ9fqVv/AX5Tzv6idBssbwpza6ISBCECV+ckBWO/zyjSTreWAWatjnLKhuDbs6cn3Jk2RUR7b5YsSGzSFwy6tOjyuyKiEKXpIlfXqtpWCbNrohIZ2x+eP1JWWHiptOyz2uyCBO+kI/LyuyKiI4VVJcaJJPfmE/k2RURWUiYskHyveFv7FZm1BarNXZ1urjki4xCWXZFRI1NllFrjopLvj1dqsyuiGjedvlxVGZXRLQvr0pW8uExeXZFRA2mprTcCnFJ9xUHlJ9mbLJM33xaXOLzyg7lpxGRzys7xS9nbf1Znl0RkUDdVkj2SVpuhTK74tb5u6wSRZSw81yFrGjeNvleIqLGZuv6o1fFJdGr5NkVEQlEd72ZKi6Jez9dll0RkSBQ+JI94pJ7Pz6mzK6IKPEbSS+7Wl6vzK6IaMvpIlnJ6RJ5OyGiWqNRL53BldkVEZmtwpI0yU4ITUpThlkEIf5jScMLWbKbc2YokFdSsrhg7bHCmnpl+xRG/13yaUYjKbIrIhI+kx4IIlqQnKvceYfzaqqlnfGBdfJeTERmi+XF7TmSrViaogyzCEKflQfEJaM/OqZsniQInZZKGsDh/OrskjpF9YR7Pj0qK1JmV0R08Iq8M075LlPRy4R9eRUFdZK0puey/cqwOmPz4p3nxUVv7smVZVdEdOxazeoDeeKSDw9dkWVXRGQRqPeKfeKSk8W66zXyMCKasTVTVjLt+6xCaT5UrDM+vjlLFnafYi8RUcqF8twyydQwddNpWXZFRN+dLkm7VCndiquy7IqIzhTrknZLTqiKdcYZW7Jlc1nKhfL30q+IS5qtwuRvM8XZFRGdLdW/+NNZ2VfM3Jotzq6IqNxgStx0Whb2+u5cWfUamyx/3XRaZ+QM5u3Wsz/miLMrIqqqN0/ZeNp6K9eMfm3tKMFalnaZu2Mam6zFda19qUxnLNXJmzgRmZqtW84oJ7b/7occ/rs+PiQZXtMvywcgm3qTpHu8f/AqdytOFUrO8refKzU2WZRhFfXma6LTsivV8syvxcOfHxO/5LcpgTZK90lhrYkbmFkomWDe2XfJTphkiJz2vTxr/Pf3Sqoz/rNj9io46x+t8259vb0oGvvZcfHLJjuZ9PpTkum/zsQfL2Tlnx/nZHVE1Cw9PuMVue8NApXXt/bzd/bl2tuMv26SDev8sJn/lOQigp2NzauV9IKT15UpAhFRobSzpF2p5IbJBqWBHxzkfyuRONmd969se1sR9e4ebrnMmzslU049r1MQ0aGrkmqX6jnJHxHJxtaXtuVwqycrGrHWzsYKtPlMa4vKKTPY29gJX0o6gr0R/sP0fPFLxaW1G86WSA5l+lX+IWuSnp9N++4MN6xZ2oCGvm/3yM7e2jphNzQ1WXnnk0Q0aYOkGZsUab3NuwckWcLXpwq5YZ8dvy5++VZqHjesWJrW/P6zDP6xEFQm0QhXrDMevCJPdIjoaH6NLD8zNfO72cwfJDnxrovy0yTbt67aL6n2Ot6JIhF9c0KyE7afLWvkNfjN0uvfx67VXONlk//IKRUnZ9UNTXtyOU0lq0h3oVwyj2yWX1+/8fbdudyta48azJbkc+XK8ovlhqwi/kjYJtpRgnW+vN7OX4QT11vndVnSKpZbyTkz+6/0Jv6YXq6X5CL2f0uVlF+r5vQEIpL139wKu1txtrS1M6Rc4LQhm+s1nCyTUzmB83O+klW6FdX1/AnMIt0JvKtXN2QXtHb1zGK7x2XP+dYN/CaTP7YSkVl+hswPs8inBDvbLo1qtnvlUxJnbLJ7YvRReusksfMiPxEnouPXa1r+fb1S/utGiybLTR0yWYO02tspN4lJ3q438zsFEX0guq7z4xm7I3J1PT+Vl7HIlpvY2QjOpbmbiGu0l4lL4/LL+X2WiDaIZsTkc3bP365WSbuznQNoubnOKNs2K7upI1tup88SUV1DayaXa3/8TMkra/n3oSs19sKUP8xxyVpQbQM/m6ySlut5F4lJccCrG/lhRMK+vNKWF6U6u42wWHTiUWkw2mt412slbaPBzglAifSLqu1sbK30KlQJ70qBrG5EVKrnb0Vjk6VGtB/KDSZ7F29Kbu4D7dWnHaqsNzdxrusSEZXo29FWtKMEq2ew3VXqsZ28W/4dHWQ3rLv9P/0Hnlreym2iIOlyOcZbeGj7i/hFZz/Oknwikv6kTt0D7Va1V3Dr4oCx3YPshUX4SBeb2Kmdyt4FEFmY9P1+vHWRRKSW7gTewv0b+oa3Lv2ODfezF3Zvj9YN/MtAzpp3G618dT1/a9XyY2Rn1JRGaeyuGJDEuTjZnR1nx7cuhn2gm7+9sLsjWhcHdAqwu6TUmd1Ur5Rtq8peC7hJ0rnfy9VuHZ4b2roweWLfcHthfi78JiSjllXbzkbIi+11Rmmxq9NNHdnIQN5ycSIimhLbuqBnbE/+WmYi6hok7Yx22p18Y2+mckSqm0vLguz0WSLyFq3p7hHsbi9sTNfWJTjDI33thUX43tRqaGfpvvfhrSsnIn9puaeWHyY74H6u/DAiNrprcMuLYN7dDDYdvVsPeoCH3QYgG8/dnPiTRai35Iu4i+iJyMdFUs69pYmIQqXlIXYWbrs6qX1F+6GDp5a7Op7zgXZ2S6id+rRDAe7OTmp+725XW9GOEqwFoyO5rcPVSR3q3drKgzycue1Dq1H9oY/dEfA/+GNf/tL456R3uIzqys8S3KUDyQvxXbhbIVt591DPIBcNp68GeWg7i8avTn4edsZk9uO0WMlrO3FTBncWv+zMuyWTiGI6SVZBLky4izvXxYRLwr5+lH+vkOytPz5uJ4zYmkdaFxG72x35afsTMeKXTir+xk6LixC/9HXjTzne0pR6elxnbpiTWjJP7n46lhtGjIJEVV8wmnM3li3ui4nSe+vszJufT5KsImf8jWVR/pIcfXA4f0YM85F0loRIzj2PRMSkScGpZ+Lt1S9BdMfJ0rH2NpYuz7tP+gX8T1tyv+R+WA8nfs4eHyWpdogHvxlLjxi9J12i3loXlSTuwAz+XYrEaKLoRsI+Hex1Rkp+UtI+7XXGZ0dK7kqzdxrTJ0xyZEdF8VN2Z+mJwVd/6scN00j3/KFn+HduEtFHj/Zq+bebk5O92XrDlP7il1reOEZE8+7tJn75eCz/vuynhkaIXy66h3+WFeYtOeI/ThvMDSMSxHcchXq5xEdy9t6wLn7hPpIPdNFwp0K27rE+4tcPdOcvA39ptKTaM4ZEcMMSYyUnJON7deDeCfjnAZIpKa6zb4QfJ6l9tG+IOMnwdXW6r1ugMmxAR2/Ziv6J/UOVYf7uzvdGc97ePrk5q8fxluT36ODRj3cnaVtpRwmWs1qddH+08oQ2eVqcLHL7k3HOakmcitH6P/X/ZfcurBrfq1ugh6zwwR5Bsla+d9bd3EsdVUmSO4PCfdxevU8+63i7OP30hHxE+GbKANkQ5qRSbXtSPot//EgvUhjW1SfYQzI67581RDkjahh9NVEy7OYvvkd5qUOjVh1/XjLHTI0Jk+VSROTmpN4rfWLCY4NC3DkDBHt/XB9Z0ZBOiumfkXI4eJFzrzhz16oTpD3/wnzlJMFcNeo1j0om1OrXx/DmdVa7VHLIPnq0t6uTSr73GF2YJ7nlZ1inIHetWhn2Yry8zokxnOs643vJh4P3x/VRHjJ3jWbygGBxSe7cUcqtYES5C0eJS47OGaZRnNKpiBW8Kkl09jwzhDdtsq2JkobXJcjd14Mz9CcOlg/NMeHeyq0I8HT2lF6i3TA5RhmmVakX3SPZe5VJDyiTE41KJXsGR3FSAieJYVT3uuSWyScGhXOTmH1PSZqxiwv1C+Gkp7Ok+ToRrRynyNgYjYzy93CWfMveZzkPFtFq2LvSflH1+v3KjVAzduaFUeKStFlDuefqZW8kiF8OjvDrr5xaGO2fLa9Mr2B35bFIiJKfQH73l4GkkBAdKHvuQ+6CeOUFRh9X5yX3SJ5KsDAhSnl7190RfrInNTw7PLJrgPxMS61i2fNGiUtiQr268H4r+HxSf3nJxH6yXCrM2+WLifKw/c9wHvLyUM+gSH/J1PDln/qF+ci/d8qgjqO7Sk4AnhkeMUKR2A3s6P036dQQ4uWy9rF+ztKj+1CPDs/HS/aJRsW+nTzAR3rRrk+I16rx8qnh00f7yp62EOyp/XqS/Jkpr90bPayL5HC7Oau//vMAL5d299im/+DDR3rLEscAd+cNkwbaOzFoE+3rMQ1EdOBy1fQfsgtrG9Uq1i3Q/R+JseG8jlRuMD/7Y86pgtomi9A7xHPVuF7dO8iTpFvy5p7crWdKyurNnXxcZg6NeHww/7eP2NXppwp1AgmMWJCntjTpXm7Ygbyq13ZdzKus99SqR3UNWD2hN/cMKbfCMHfbuewSvYbRoDDvD3/fuwPv8mZmUU38x8caTM0Co//w6J3KhoaQv+1rtlqJGJEwINgzUzoqteixbG9uRYOVCSrGYsK8ZNlVi3fSrnxwOK/KYHLXahLuCtg0OYb7HKz712bsuVhuuzdNxdjp54eIfx9ssTw97+VtFwSykkAqFa35fb/pd3NOapNzK8evOyZYiUhgjD3YLSj5Kc7ZqslEIUtTauqbiQmM2L1RgbtmyhNxm8BXd1U2mIkRCRTg5lzxBv8JUveuPZ6WWyGQQALzddeUvDKG+xyssesydlwsFwSBiDEV7XkqLoF32vddVkHixqwmCyMSNGr294n9nhjEaVEZhZVDVx+3kpWIGLEx0UE7ZnA21mAgnyX/vlGfsSB3bdkSfsOLXZ2eWayzCoJKYNGBdh+qFPrarpJ6s62dMKa6/tqIMC/Oad8fN2RuPV1ke+obY2xL4oA/8C73Lt9z8eWU3BtPOGNs4oDQTZM5c/PFyoZey9IsJJCgIiaM6CJ/LkCL4KQ95XqTrZcNCvM68QK/fQYs3l1lNBERCcxZTabl8qcb2EzZdGrjqRLbOOeh1Vx5eXQg7xL4kp2XXk+7YFvFp1ap/vlE3NgenGZ846F0ZovAyFmtWv1wj6fv5jzhrKi6MfLtNLPV9sA0Ib5rwIFZ/Oe0hSWlFuuNAhOYQL1CvHJekt/Jb9Nv1YHsYr3t10dvrVOt9MElLd7cfWHp3iumZgsj1sHD+dQLw0N4z8FavPPSW6kXBCLbpcVPHus9k3fRJbeyYfgH6VUNzQKRq5NqxfieTw/lhBnM5qi3D5QbjIJAamKPDgj+bnKMMoyIVh/I23CqqFhv6uilfTy20zO8p2oR0fztZ9ccud7Y3KxRqfuHeh96Zhj3OVjP/ZjzyeFrFkEgRi4qVcacEX14Vy9qG5u+PFFwsqBWIIoN95kaG+7D+4Wx1GCM/+jwtWqjRRC8XDQrx/V8YjD/OVivpFxIPldaVW/u7Os2d3TXR+38cvLJkfz1GQWFdcYQT+3kQR3n8h77R0TnywzfZhaeK9N38NT+LirgD31DuClCic64/kRBVpHOQ6se0tn3L4PCXHm/V+ptj4a6XttkFWLCvKfGhvvbeQ7WptPFh65WVTc09Q72nBobzr1Idqtu52MaiKjebPnqREFGQa2xyTIwzPvx2E6BHje1MuGX+QX5T7tLsKC9KS4uDgoK0nBHOIA7ksFgMJvNfn52FxcC3IFuc4J1m/1vPwcLAAAA4LcBCRYAAACAgyHBAgAAAHAwJFgAAAAADoYECwAAAMDBkGABAAAAOBgSLAAAAAAHQ4IFAAAA4GBIsAAAAAAcDAkWAAAAgIMhwQIAAABwMCRYAAAAAA6GBAsAAADAwZBgAQAAADiY5pai8/Pz8/Pzk5KSfp3KQHuk1+vd3d1VKuTiADeYzWaLxeLq6trWFQFoR3Q6naenJ2OsrSvyq9i/f39ERMQtveXWZs3+/fvf6hfA/7pz586ZTKa2rgVAO1JVVVVQUNDWtQBoX3JyciwWS1vX4tcSERHRv3//W3oLEwThV6oN/DZERUWlpKRERUW1dUUA2ot169ZlZGSsW7eurSsC0I74+fldvnzZz8+vrSvSXuB3HwAAAAAHQ4IFAAAA4GBIsAAAAAAcDAkWAAAAgIOp8cwF+K/i4uJwRzpAC8ZYaGhot27d2roiAO3L8OHDnZyc2roW7QXuIgQAAABwMPxECAAAAOBgSLAAAAAAHAwJFgAAAICDIcECAAAAcDAkWMCXnZ197NgxWWFeXl5KSkpZWVmbVAmgreh0uj179mRkZFitVtmf0CngzmS1WjMzM5OTk3Nzc5V/Rb8gIhIAFIqLiwMDAydPntxSYjQax48fT0QuLi5EtHjx4jasHsDttHz5cpVKpdVqiSguLq6mpsZWjk4Bd6z8/Hzb//nY2dmZiCZMmGA0Gm1/Qr9ogStYICcIQmJiYkVFhbhwyZIl+/btO3LkSH19/RdffLF06dKffvqprWoIcNts3rz5lVde2bhxY319/ZEjR86ePbtw4ULbn9Ap4I41c+bMxsbG48ePGwyGn376affu3cuWLbP9Cf2iBZ6DBXLLly9ft26di4tLv379NmzYQEQWiyU8PHzy5MkrVqywxYwaNcrb2/uO7TZw5xg+fHj37t0/++wz28svv/zy7NmzK1asQKeAO5mHh8eiRYsWLVpkezl+/PiGhobU1FT0CzFcwQKJkydPLlmyZOPGje7u7i2F165dKykpSUhIaClJSEg4cuRIW1QQ4Papqqo6fPjwww8/TES21VdTp061zRzoFHAni46Ozs7Otv27qanpwoUL0dHRhH4hhQQLWhkMhkmTJr366quxsbHi8tLSUiLq0KFDS0lwcHBVVVVzc/PtriLAbVRUVEREer1++PDhbm5uISEh8+bNMxqNhE4Bd7b3338/LS2tb9++06dPj4yM1Gq1tp/O0S/EkGBBq9mzZ4eFhc2fP19WXltbS0Senp4tJZ6enoIg1NTU3Nb6Adxettli9uzZ48aN27Vr14IFC9asWTNnzhxCp4A7m5ubm7u7e3Nzc0lJiSAIfn5+ttXu6BdimrauALQXW7Zs2b59+5kzZ1Qqedrt7+9PRHq9vqWkrq6OMebj43Nbqwhwe9nmjIULF86bN4+IRo4c2djYuHjx4tWrV6NTwB1Lp9ONGDHiueeesy1sN5lMEyZMGDt27IkTJ9AvxHAFC244fPhwTU1NRESERqPRaDTHjx/fuHGjRqPZtm1bcHAw/fts3qa0tDQwMBD/13T4bQsJCSGiwYMHt5QMGjTIarVeu3YNnQLuWHv27GlsbLRdyiUirVY7a9askydPFhcXo1+IIcGCG2bOnLljx47kf+vevfvo0aOTk5OHDBnSqVOnLl26pKamtgSnpqbGx8e3YW0BboMuXbr4+/vn5OS0lJw/f16tVkdERKBTwB3LdgtUZWVlS4nt366urugXEm35EC5ox+Li4sQPGn377bfd3d0PHjzY1NS0du1axlhaWlobVg/g9pg/f35AQMCOHTv0ev3OnTv9/f2ffPJJ25/QKeDOpNfrO3fuPHTo0JycnPr6+tTU1I4dOz744IO2v6JftECCBXyyBMtiscyYMUOlUjk5OWm12k8++aQN6wZw25hMpsTERMaY7Yx0ypQpOp3O9id0CrhjZWdnx8TEtFypeeSRRyoqKmx/Qr9ogQeNwi3Q6XR5eXk9e/a0/W9DAO4QOp3u0qVLkZGRvr6+yj+hU8CdqbCwsKSkJDIy0ra2XQz9gvAkdwAAAACHwyJ3AAAAAAdDggUAAADgYEiwAAAAABwMCRYAAACAgyHBAgAAAHAwJFgAAAAADoYECwAAAMDBkGABABGnhccAAABOSURBVAAAOBgSLAAAAAAHQ4IFAAAA4GBIsAAAAAAcDAkWAAAAgIMhwQIAAABwMCRYAAAAAA6GBAsAAADAwZBgAQAAADgYEiwAAAAAB/s/PgPw93k63uMAAAAASUVORK5CYII=\"/>\n\n\n<div class=\"markdown\"><p>The default random forest algorithm is allowed to choose any location inside this feature to split on. To avoid having to figure out locations by itself, the algorithm will choose on of the datapoints as a split location. So, for example, the following split indicated by the red vertical line would be a valid choice:</p></div>\n\n\n\n\n\n<img src=\"data:image/png;base64,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\"/>\n\n\n<div class=\"markdown\"><p>But what happens if we take a random subset of the data? Say, we take the following subset of length <code>0.7 * length(nodes)</code>:</p></div>\n\n\n\n\n\n\n\n\n<img src=\"data:image/png;base64,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\"/>\n\n\n<div class=\"markdown\"><p>Now, the algorithm would choose a different location and, hence, introduce instability. To solve this, Bénard et al. decided to limit the splitpoints that the algorithm can use to split to data to a pre-defined set of points. For each feature, they find <code>q</code> empirical quantiles where <code>q</code> is typically 10. Let's overlay these quantiles on top of the <code>age</code> feature:</p></div>\n\n\n<img src=\"data:image/png;base64,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\"/>\n\n\n<div class=\"markdown\"><p>Next, let's see where the cutpoints are when we take the same random subset as above:</p></div>\n\n\n<img src=\"data:image/png;base64,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\"/>\n\n\n<div class=\"markdown\"><p>As can be seen, many cutpoints are at the same location as before. Furthermore, compared to the unrestricted range, the chance that two different trees who see a different random subset of the data will select the same cutpoint has increased dramatically.</p><p>The benefit of this is that it is now quite easy to extract the most important rules. Rule extraction consists of simplifying them a bit and ordering them by frequency of occurrence. Let's see how accurate this model is.</p></div>\n\n","category":"page"},{"location":"binary-classification/#Benchmarks","page":"Simple Binary Classification","title":"Benchmarks","text":"","category":"section"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<div class=\"markdown\">\n<p>Let's compare the following models:</p><ul><li><p>Decision tree (<code>DecisionTreeClassifier</code>)</p></li><li><p>Stabilized random forest (<code>StableForestClassifier</code>)</p></li><li><p>SIRUS (<code>StableRulesClassifier</code>)</p></li><li><p>LightGBM (<code>LGBMClassifier</code>)</p></li></ul><p>The latter is a state-of-the-art gradient boosting model created by Microsoft. See the Appendix for more details about these results.</p></div>\n\n<pre class='language-julia'><code class='language-julia'>e1 = let\n    model = DecisionTreeClassifier\n    hyperparameters = (; max_depth=2, rng=_rng())\n    _evaluate(model, hyperparameters, X, y)\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>e2 = let\n    model = StableRulesClassifier\n    hyperparameters = (; max_depth=2, max_rules=8, rng=_rng())\n    _evaluate(model, hyperparameters, X, y)\nend</code></pre>\n<pre class=\"code-output documenter-example-output\" id=\"var-e2\">(e = PerformanceEvaluation(0.665,),\n row = (Model = \"StableRulesClassifier\",\n        Hyperparameters = \"(max_depth = 2, max_rules = 8)\",\n        AUC = 0.66,\n        se = 0.08,),)</pre>\n\n<pre class='language-julia'><code class='language-julia'>e3 = let\n    model = StableRulesClassifier\n    hyperparameters = (; max_depth=2, max_rules=25, rng=_rng())\n    _evaluate(model, hyperparameters, X, y)\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>e4 = let\n    model = StableRulesClassifier\n    hyperparameters = (; max_depth=1, max_rules=25, rng=_rng())\n    _evaluate(model, hyperparameters, X, y)\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>e5 = let\n    model = StableForestClassifier\n    hyperparameters = (; max_depth=2, rng=_rng())\n    _evaluate(model, hyperparameters, X, y)\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>e6 = let\n    model = LGBMClassifier\n    hyperparameters = (;)\n    _evaluate(model, hyperparameters, X, y)\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>e7 = let\n    model = LGBMClassifier\n    hyperparameters = (; max_depth=2)\n    _evaluate(model, hyperparameters, X, y)\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>#hideall\nresults = let\n    df = DataFrame(getproperty.([e6, e7, e1, e5, e3, e2, e4], :row))\n    df[!, :Interpretability] = [\"Medium\", \"Medium\", \"High\", \"Low\", \"High\", \"High\", \"High\"]\n    df[!, :Stability] = [\"High\", \"High\", \"Low\", \"High\", \"High\", \"High\", \"High\"]\n    df[!, :AUC] = map(df.AUC) do score\n        text = string(score)\n        length(text) &lt; 4 ? text * '0' : text\n    end\n    rename!(df, :se =&gt; \"1.96*SE\")\nend</code></pre>\n<table><tbody><tr><th></th><th>Model</th><th>Hyperparameters</th><th>AUC</th><th>1.96*SE</th><th>Interpretability</th><th>Stability</th></tr><tr><td>1</td><td>\"LGBMClassifier\"</td><td>\"(;)\"</td><td>\"0.71\"</td><td>0.06</td><td>\"Medium\"</td><td>\"High\"</td></tr><tr><td>2</td><td>\"LGBMClassifier\"</td><td>\"(max_depth = 2,)\"</td><td>\"0.67\"</td><td>0.05</td><td>\"Medium\"</td><td>\"High\"</td></tr><tr><td>3</td><td>\"DecisionTreeClassifier\"</td><td>\"(max_depth = 2,)\"</td><td>\"0.63\"</td><td>0.06</td><td>\"High\"</td><td>\"Low\"</td></tr><tr><td>4</td><td>\"StableForestClassifier\"</td><td>\"(max_depth = 2,)\"</td><td>\"0.71\"</td><td>0.05</td><td>\"Low\"</td><td>\"High\"</td></tr><tr><td>5</td><td>\"StableRulesClassifier\"</td><td>\"(max_depth = 2, max_rules = 25)\"</td><td>\"0.70\"</td><td>0.09</td><td>\"High\"</td><td>\"High\"</td></tr><tr><td>6</td><td>\"StableRulesClassifier\"</td><td>\"(max_depth = 2, max_rules = 8)\"</td><td>\"0.66\"</td><td>0.08</td><td>\"High\"</td><td>\"High\"</td></tr><tr><td>7</td><td>\"StableRulesClassifier\"</td><td>\"(max_depth = 1, max_rules = 25)\"</td><td>\"0.67\"</td><td>0.07</td><td>\"High\"</td><td>\"High\"</td></tr></tbody></table>\n\n\n<div class=\"markdown\"><p>As can be seen, the score of the stabilized random forest (<code>StableForestClassifier</code>) is almost as good as Microsoft's state-of-the-art classifier (<code>LGBMClassifier</code>), but both are not interpretable since that requires interpreting thousands of trees. With the rule-based classifier (<code>StableRulesClassifier</code>), a small amount of predictive performance can be traded for high interpretability. Note that the rule-based classifier may actually be more accurate in practice because verifying and debugging the model is much easier.</p><p>Regarding the hyperparameters, tuning <code>max_rules</code> and <code>max_depth</code> has the most effect. <code>max_rules</code> specifies the number of rules to which the random forest is simplified. Setting to a high number such as 999 makes the predictive performance similar to that of a random forest, but also makes the interpretability as bad as a random forest. Therefore, it makes more sense to truncate the rules to somewhere in the range 5 to 40 to obtain accurate models with high interpretability. <code>max_depth</code> specifies how many levels the trees have. For larger datasets, <code>max_depth=2</code> makes the most sense since it can find more complex patterns in the data. For smaller datasets, <code>max_depth=1</code> makes more sense since it reduces the chance of overfitting. It also simplifies the rules because with <code>max_depth=1</code>, the rule will contain only one conditional (for example, \"if A then ...\") versus two conditionals (for example, \"if A &amp; B then ...\"). In some cases, model accuracy can be improved by increasing <code>n_trees</code>. The higher this number, the more trees are fitted and, hence, the higher the chance that the right rules are extracted from the trees.</p></div>\n\n","category":"page"},{"location":"binary-classification/#Interpretation","page":"Simple Binary Classification","title":"Interpretation","text":"","category":"section"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<div class=\"markdown\">\n<p>Finally, let's interpret the rules that the model has learned. Since we know that the model performs well on the cross-validations, we can fit our preferred model on the complete dataset:</p></div>\n\n<pre class='language-julia'><code class='language-julia'>let\n    model = StableRulesClassifier(; max_depth=2, max_rules=8, rng=_rng())\n    mach = machine(model, X, y)\n    fit!(mach)\n    mach.fitresult\nend</code></pre>\n<pre class=\"code-output documenter-example-output\" id=\"var-hash172047\">StableRules model with 8 rules:\n if X[i, :nodes] &lt; 8.0 then 0.156 else 0.031 +\n if X[i, :nodes] &lt; 14.0 then 0.164 else 0.026 +\n if X[i, :nodes] &lt; 4.0 then 0.128 else 0.037 +\n if X[i, :nodes] ≥ 8.0 &amp; X[i, :age] &lt; 38.0 then 0.0 else 0.008 +\n if X[i, :year] ≥ 1966.0 &amp; X[i, :age] &lt; 42.0 then 0.0 else 0.005 +\n if X[i, :nodes] &lt; 2.0 then 0.107 else 0.034 +\n if X[i, :year] ≥ 1966.0 &amp; X[i, :age] &lt; 38.0 then 0.0 else 0.001 +\n if X[i, :year] &lt; 1959.0 &amp; X[i, :nodes] ≥ 2.0 then 0.0 else 0.003\nand 2 classes: [0.0, 1.0]. \nNote: showing only the probability for class 1.0 since class 0.0 has probability 1 - p.\n</pre>\n\n\n<div class=\"markdown\"><p>The interpretation of the fitted model is as follows. The model has learned three rules for this dataset. For making a prediction for some value at row <code>i</code>, the model will first look at the value for the <code>nodes</code> feature. If the value is below the listed number, then the number after <code>then</code> is chosen and otherwise the number after <code>else</code>. This is done for all the rules and, finally, the rules are summed to obtain the final prediction.</p></div>\n\n","category":"page"},{"location":"binary-classification/#Visualization","page":"Simple Binary Classification","title":"Visualization","text":"","category":"section"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<div class=\"markdown\">\n<p>Since our rules are relatively simple with only a binary outcome and only one clause in each rule, the following figure is a way to visualize the obtained rules per fold. For multiple clauses, I would not know how to visualize the rules. Also, this plot is probably not perfect; let me know if you have suggestions.</p><p>This figure shows the model uncertainty. The x-position on the left shows <code>log(else-scores / if-scores)</code>, the vertical lines on the right show the threshold, and the histograms on the right show the data.  For example, for the <code>nodes</code>, it can be seen that all rules (fitted in the different cross-validation folds) base their decision on whether the <code>nodes</code> are below, roughly, 5.  Next, the left side indicates that the individuals who had less than 5 nodes are more likely to survive, according to the model.  The sizes of the dots indicate the weight that the rule has, so a bigger dot means that a rule plays a larger role in the final outcome.  These dots are sized in such a way that a doubling in weight means a doubling in surface size.  Finally, the variables are ordered by the sum of the weights.</p></div>\n\n\n\n\n\n\n\n\n<img src=\"data:image/png;base64,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\"/>\n\n\n<div class=\"markdown\"><p>What this plot shows is that the <code>nodes</code> feature is on average chosen as the feature with the most predictive power. This can be concluded because the <code>nodes</code> feature is shown as the first feature and the tickness of the dots is the biggest. Furthermore, there is agreement on the effect of the <code>nodes</code> and <code>age</code> features. In both cases, a lower number is associated with survival. This is as expected because the model essentially implies that people where less cancerous auxillary nodes are detected and who are younger are more likely to survive. The <code>year</code> in which the operation was conducted shouldn't have serious effect on the survivability and the model shoes this by a high variability on that feature.</p></div>\n\n","category":"page"},{"location":"binary-classification/#Practical-applications","page":"Simple Binary Classification","title":"Practical applications","text":"","category":"section"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<div class=\"markdown\">\n<p>As shown in the previous sections, the model satisfies two things:</p><ol><li><p>It shows a good predictive performance in the model evaluations. The performance is slightly lower than more complex models, but this tradeoff can be worth it because the rule-based model is interpretable.</p></li><li><p>The fitted model makes theoretical sense. As shown in the visualization, the <code>nodes</code> and <code>age</code> features are the most important for prediction and both features are used in the expected way.</p></li></ol><p>Since the model shows good performance and makes theoretical sense, we can be reasonably sure that the model will generalize to new data in a similar context. Next, the model can be applied by fitting it on the full dataset and brining it to a real-world setting.</p><p>Note that unlike the state-of-the-art random forest from Microsoft, each decision that the model makes can be fully explained. All rules can be read stand-alone and interpreted. For example, when trying to interpret a random forest, it will only report feature importances. For the Haberman dataset, we would know more than <code>nodes</code> is negatively associated and <code>age</code> too. With the rule-based model, we can say exactly at which number of <code>nodes</code> and at which <code>age</code> the model decides to split the data between likely to survive or not survive.</p></div>\n\n","category":"page"},{"location":"binary-classification/#Conclusion","page":"Simple Binary Classification","title":"Conclusion","text":"","category":"section"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<div class=\"markdown\">\n<p>Compared to decision trees, the rule-based classifier is more stable, more accurate and similarly easy to interpet. Compared to the random forest, the rule-based classifier is only slightly less accurate, but much easier to interpet. Due to the interpretability, it is likely easier to verify the model and therefore the rule-based classifier will be more accurate in real-world settings. This makes rule-based highly suitable for many machine learning tasks.</p></div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n","category":"page"},{"location":"binary-classification/#Appendix","page":"Simple Binary Classification","title":"Appendix","text":"","category":"section"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"<div class=\"markdown\">\n</div>\n\n<pre class='language-julia'><code class='language-julia'>begin\n    ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\"\n\n    using CairoMakie\n    using CategoricalArrays: categorical\n    using CSV: CSV\n    using DataDeps: DataDeps, DataDep, @datadep_str\n    using DataFrames\n    using DecisionTree: DecisionTree\n    using LightGBM.MLJInterface: LGBMClassifier\n    using MLJDecisionTreeInterface: DecisionTreeClassifier\n    using MLJ: CV, MLJ, Not, PerformanceEvaluation, auc, fit!, evaluate, machine\n    using StableRNGs: StableRNG\n    using SIRUS\n    using Statistics: mean, std\nend</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>function _plot_cutpoints(data::AbstractVector)\n    fig = Figure(; resolution=(800, 100))\n    ax = Axis(fig[1, 1])\n    cps = Float64.(unique(cutpoints(data, 10)))\n    scatter!(ax, data, fill(1, length(data)))\n    vlines!(ax, cps; color=:black, linestyle=:dash)\n    textlocs = [(c, 1.1) for c in cps]\n    for cutpoint in cps\n        annotation = string(round(cutpoint; digits=2))::String\n        text!(ax, cutpoint + 0.2, 1.08; text=annotation, fontsize=13)\n    end\n    ylims!(ax, 0.9, 1.2)\n    hideydecorations!(ax)\n    return fig\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>_rng(seed::Int=1) = StableRNG(seed);</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>function _io2text(f::Function)\n    io = IOBuffer()\n    f(io)\n    s = String(take!(io))\n    return Base.Text(s)\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>function _evaluate(model, X, y; nfolds=10)\n    resampling = CV(; nfolds, shuffle=true, rng=_rng())\n    acceleration = MLJ.CPUThreads()\n    evaluate(model, X, y; acceleration, verbosity=0, resampling, measure=auc)\nend;</code></pre>\n\n\n\n\n\n<pre class='language-julia'><code class='language-julia'>function register_haberman()\n    name = \"Haberman\"\n    message = \"Slightly modified copy of Haberman's Survival Data Set\"\n    remote_path = \"https://github.com/rikhuijzer/haberman-survival-dataset/releases/download/v1.0.0/haberman.csv\"\n    checksum = \"a7e9aeb249e11ac17c2b8ea4fdafd5c9392219d27cb819ffaeb8a869eb727a0f\"\n    DataDeps.register(DataDep(name, message, remote_path, checksum))\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>function _haberman()\n    register_haberman()\n    dir = datadep\"Haberman\"\n    path = joinpath(dir, \"haberman.csv\")\n    df = CSV.read(path, DataFrame)\n    df[!, :survival] = categorical(df.survival)\n    # Need Floats for the LGBMClassifier.\n    for col in [:age, :year, :nodes]\n        df[!, col] = float.(df[:, col])\n    end\n    return df\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>_filter_rng(hyper::NamedTuple) = Base.structdiff(hyper, (; rng=:foo));</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>_pretty_name(modeltype) = last(split(string(modeltype), '.'));</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>function _evaluate(modeltype, hyperparameters, X, y)\n    model = modeltype(; hyperparameters...)\n    e = _evaluate(model, X, y)\n    row = (;\n        Model=_pretty_name(modeltype),\n        Hyperparameters=_hyper2str(_filter_rng(hyperparameters)),\n        AUC=_score(e),\n        se=round(only(MLJ.MLJBase._standard_errors(e)); digits=2)\n    )\n    (; e, row)\nend;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>_hyper2str(hyper::NamedTuple) = hyper == (;) ? \"(;)\" : string(hyper)::String;</code></pre>\n\n\n<pre class='language-julia'><code class='language-julia'>function _score(e::PerformanceEvaluation)\n    return round(only(e.measurement); digits=2)\nend;</code></pre>\n\n\n<!-- PlutoStaticHTML.End -->","category":"page"},{"location":"binary-classification/","page":"Simple Binary Classification","title":"Simple Binary Classification","text":"EditURL = \"https://github.com/rikhuijzer/SIRUS.jl/blob/main/docs/src/binary-classification.jl\"","category":"page"},{"location":"#SIRUS","page":"SIRUS","title":"SIRUS","text":"","category":"section"},{"location":"","page":"SIRUS","title":"SIRUS","text":"This package is a pure Julia implementation of the Stable and Interpretable RUle Sets (SIRUS) algorithm. The algorithm was originally created by Clément Bénard, Gérard Biau, Sébastien Da Veiga, and Erwan Scornet (Bénard et al., 2021). SIRUS.jl has implemented both classification and regression. Performance is generally the best on binary classification tasks.","category":"page"},{"location":"","page":"SIRUS","title":"SIRUS","text":"For R users, the original version of the SIRUS algorithm is available via CRAN. Compared to the R version, this Julia implementation is more easy to inspect than the original R and C++ implementation. Furthermore, this implementation is fast and integrated with the MLJ.jl machine learning ecosystem. With this, multiple benchmarks are executed and checked with every test run. The results are listed in the GitHub Actions summary.","category":"page"},{"location":"","page":"SIRUS","title":"SIRUS","text":"The algorithm is based on random forests. Random forests perform generally very well; especially on datsets with a relatively high number of features compared to the number of datapoints (Biau & Scornet, 2016). However, random forests are hard to interpret because of the large number of, sometimes large, trees. Interpretability methods such as SHAP alleviate this problem slightly, but still do not fully explain predictions. Put differently, it is not possible to reproduce predictions on the feature importances that SHAP reports. SIRUS solved this by converting the large number of trees to interpretable rules. These rules fully explain the predictions while remaining easy to interpret.","category":"page"},{"location":"#Where-to-Start?","page":"SIRUS","title":"Where to Start?","text":"","category":"section"},{"location":"","page":"SIRUS","title":"SIRUS","text":"Binary Classification Example","category":"page"},{"location":"#Acknowledgements","page":"SIRUS","title":"Acknowledgements","text":"","category":"section"},{"location":"","page":"SIRUS","title":"SIRUS","text":"Thanks to Clément Bénard, Gérard Biau, Sébastian da Veiga and Erwan Scornet for creating the SIRUS algorithm and documenting it extensively. Special thanks to Clément Bénard for answering my questions regarding the implementation. Thanks to Hylke Donker for figuring out a way to visualize these rules. Also thanks to my PhD supervisors Ruud den Hartigh, Peter de Jonge and Frank Blaauw, and Age de Wit and colleagues at the Dutch Ministry of Defence for providing the data clarifying the constraints of the problem and for providing many methodological suggestions.","category":"page"},{"location":"implementation-overview/#Implementation-Overview","page":"Implementation Overview","title":"Implementation Overview","text":"","category":"section"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"This page provides a high-level overview of the implementation. In essence, this overview is a combination of three things:","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"Section 8.1.1 Regression Trees and 8.1.2 Classification trees (James et al., 2021).\nThe SIRUS algorithm description (Bénard et al., 2021).\nSome implementation details, as obtained by trial and error and by correspondence with Clément Bénard, which were missing from aforementioned sources.","category":"page"},{"location":"implementation-overview/#Fit-Stabilized-Trees","page":"Implementation Overview","title":"Fit Stabilized Trees","text":"","category":"section"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"The tree fitting procedure is very similar to the algorithm explanation in James et al. (2021). In summary:","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"First, fit a large number of trees where for each tree a subset is taken from the observations and the features. These subsets make the trees less correlated and it has been empirically shown that this improves predictive performance. Specifically, the subsets are as follows:","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"For the subset of observations, take partial_sampling (default: 0.7) * n random observations from the original dataset.   Sample these observations with replacement.\nFor the subset of features, take sqrt(p) random features from the original dataset, where p is the number of features.   Samples these features without replacement.   Note that the subset of features is chosen at each split of the tree and not only once for each tree.   If you choose the subset only at the start of the tree building, then an important feature might not end up in the tree at all, which results in poor predictive performance.   So, chosing this at each split is the best of both worlds since it (1) avoids that each tree splits the root node on the same feature and (2) does still allow the important features to all be used inside the tree.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"Before continuing with the algorithm description, we need a small digression on the splitpoints that the algorithm uses. What is different in the SIRUS algorithm compared to vanilla random forest implementations, is that the SIRUS algorithm calculates the splitpoints before splitting. These splitpoints are calculated over the whole dataset and then the location of the splits are restricted to these pre-determined splitpoints. In other words, the location of the splits is only allowed to be on one of the pre-determined splitpoints. Regarding the splitpoints calculation, the splitpoints are calculated by taking q-empirical quantiles. Simply put, taking q-empirical quantiles means determining q quantiles (splitpoints) which divide the dataset in nearly equal sizes. The empirical part denotes that we determine the quantiles for data instead of a probability distribution.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"On this subset, then fit a tree. For both trees, we apply the top-down, greedy approach of recursive binary splitting, where each split aims to find the best split point. Finding the best splitpoint means looping through each possible splitpoint from the aforementioned set of pre-determined splitpoints and for each splitpoint determine two half-planes (or regions). In the left half-plane, take all the points in the feature under consideration which are lower than the splitpoint, that is, R_1 =  X    X_j  s  . In the right half-plane, take all the points in the feature under consideration which are higher or equal than the splitpoint, that is, R_2 =  X    X_j geq s  . Then for each of this combination of two half-planes, find the best splitpoint. Finding the best splitpoint boils down to find the split which \"summarizes\" the data in the best way. For regression, the best split point is found by finding the splitpoint for which we lose the least information when taking the average of R_1 and R_2. More formally, the split is found by minimizing the Residual Sum of Squares (RSS):","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"sum_x_i in R_1 (y_i - haty_R_1)^2 + sum_x_i in R_2 (y_i - haty_R_2)^2","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"where haty_R_1 and haty_R_2 denote the mean response for the training observations in respectively R_1 and R_2. For classification, the best split point is found by determining the classes beforehand and then using these to calculate the Gini index. The Gini index is needed because classification deals with an unordered set of classes. The Gini index is a way to determine the most informative splitpoint via node purity and defined as:","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"1 - sum_textclass in textclasses p_textclass^2","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"where p_textclasses denotes the fraction (proportion) of items from the current region that are from class. Note that this equation is optimized for computational efficiency. For the full derivation from the original equation, see Gini impurity at Wikipedia.","category":"page"},{"location":"implementation-overview/#Rule-Generation","page":"Implementation Overview","title":"Rule Generation","text":"","category":"section"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"After creating many trees, the SIRUS algorithm converts these trees to rules. One of the first of such rule-based models was the RuleFit algorithm (Friedman & Popescu, 2008). The idea behind these models is that any tree can be expressed as a set of rules. For example, say we have the following tree with nodes n_1 n_2  n_5.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"using CairoMakie\n\nempty_theme = Theme(\n    Axis = (\n        backgroundcolor = :transparent,\n        leftspinevisible = false,\n        rightspinevisible = false,\n        bottomspinevisible = false,\n        topspinevisible = false,\n        xticklabelsvisible = false,\n        yticklabelsvisible = false,\n        xgridcolor = :transparent,\n        ygridcolor = :transparent,\n        xminorticksvisible = false,\n        yminorticksvisible = false,\n        xticksvisible = false,\n        yticksvisible = false,\n        xautolimitmargin = (0.0,0.0),\n        yautolimitmargin = (0.0,0.0),\n    )\n)\n\nfunction plot_tree()\n    with_theme(empty_theme) do\n        fig = Figure()\n        ax = Axis(fig[1, 1])\n        linesopts = (\n            color = :black,\n            space = :relative,\n        )\n        scatteropts = (\n            color = :white,\n            markersize = 100,\n            strokewidth = 2,\n            space = :relative,\n            transparency = true\n        )\n        textopts = (\n            space = :relative,\n            fontsize = 30,\n            justification = :center,\n            align = (:center, :center)\n        )\n\n        lines!(ax, [0.5, 0.3], [0.9, 0.5]; linesopts...)\n        lines!(ax, [0.5, 0.7], [0.9, 0.5]; linesopts...)\n\n        lines!(ax, [0.3, 0.12], [0.5, 0.1]; linesopts...)\n        lines!(ax, [0.3, 0.48], [0.5, 0.1]; linesopts...)\n\n        scatter!(ax, 0.5, 0.9; scatteropts...)\n        text!(ax, 0.5, 0.9; text=L\"n_1\", textopts...)\n        scatter!(ax, 0.3, 0.5; scatteropts...)\n        text!(ax, 0.3, 0.5; text=L\"n_2\", textopts...)\n        scatter!(ax, 0.7, 0.5; scatteropts...)\n        text!(ax, 0.7, 0.5; text=L\"n_3\", textopts...)\n\n        scatter!(ax, 0.12, 0.1; scatteropts...)\n        text!(ax, 0.12, 0.1; text=L\"n_4\", textopts...)\n        scatter!(ax, 0.48, 0.1; scatteropts...)\n        text!(ax, 0.48, 0.1; text=L\"n_5\", textopts...)\n\n        text!(ax, 0.35, 0.75; text=L\"x_1 < 3\", textopts...)\n        text!(ax, 0.65, 0.75; text=L\"x_1 \\geq 3\", textopts...)\n\n        text!(ax, 0.16, 0.33; text=L\"x_2 < 5\", textopts...)\n        text!(ax, 0.45, 0.33; text=L\"x_2 \\geq 5\", textopts...)\n\n        hidedecorations!(ax)\n        return fig\n    end\nend","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"plot_tree() # hide","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"and say that this tree was generated from a tree fitting procedure as described above. From this representation, we can see that node n_1 splits the feature x_1 on 3. If x_1  3, then the prediction will go to n_2 and if x geq 3, then the prediction will take the content of n_3. In n_2, the prediction will be made based on n_4 or n_5 depending on whether feature x_2 is smaller than or greater or equal to 5.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"To convert such a tree to rules, note that each path to a leaf can be converted to one rule. For example, the path to n_3 can be converted to","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"textif  x_1 geq 3 text then  A text else  B","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"where A considers all points that satisfy the rule constraints represented by the path to n_3 (x_1 geq 3) and B considers all points that do not satisfy the rule constraints (x_1  3). Similarly, the path to n_4 can be converted to","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"textif  x_1  3    x_2  5 text then  C text else  D","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"where C considers all the points that satisfy the rule constraints and D considers all the points that do not satisfy the rule constraints.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"Unlike regular decision trees, rule-based models are typically restricted to a depth of 2 for reasons that will be explained later. For now, say we have a large number of trees, typically around 1500, with a depth of at most 2, then we can estimate that the number of generated rules will be at most 6 * 1500 = 9000. I'm taking 6 here since a tree of depth 2 can have at most 7 nodes, of which all but the root are converted to a separate rule. In other words, \"both internal and external nodes are extracted from the trees of the random forest to generate a large collection of rules, typically 10^4\" (Bénard et al., 2021, Section Rule generation).","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"Obviously, thousands of rules are not interpretable. Just like random forests, each prediction can be traced back to exactly how it was made. However, thousands of additions and multiplications are hard to interpret and explain. That's why visualizations based on SHAP are often used (e.g., Molnar, 2023). Still, these visualizations simplify the model such that feature importances becomes explainable, but they do not fully explain how predictions are made. The SIRUS algorithm solves that by simplifying the model itself instead of only simplifying the model explanation.","category":"page"},{"location":"implementation-overview/#Rule-Selection-and-Post-Treatment","page":"Implementation Overview","title":"Rule Selection and Post-Treatment","text":"","category":"section"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"The aim of rule selection is to remove as many rules as possible without affecting the predictive performance too much. This is similar to the Tree Pruning that happens in Random Forests (James et al., 2021; Section 8.1). This is also similar to pruning in artificial neural networks, where the least important neurons are removed. In the SIRUS algorithm, this pruning is done via two ways. Firstly, by pruning the many identical rules in the different forests, which are identical thanks to tree stabilization done when building the trees. The tree stabilization makes the rules identical because the splitpoints are identical in the different trees. For example, the stabilization could result in the rules textif  x_1  3 text then   text else   and textif  x_1  3 text then   text else   both existing in different trees. Secondly, by pruning rules which are a linear combination of other rules.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"The first step requires setting a hyperparameter p_0 in the original algorithm. This hyperparameter specifies a threshold which is then used to remove rules with a occurence frequency below p_0. The implementation in this Julia package ignores this step because it is superseeded by the second step and because it is quite difficult to pick the right p_0. In other words, this step is ignored because it seems like a premature optimization (but I'm happy to be proven wrong of course).","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"The second step is more important and more involved. As said before, the second step is to remove the least important linear combinations of other rules. An example of this is shown in the original paper (Bénard et al., 2021, Table 3 (the second) in Section 4 Post-treatment Illustration of the Supplementary PDF), which is repeated here:","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"Rule Number If Clause Then Else Remove Reason\n1 x_1  32000 61 408  \n2 x_1 geq 32000 408 61 yes rule 1\n3 x_2  8000 62 386  \n4 x_2 geq 8000 386 62 yes rule 3\n5 x_3  64 56 334  \n6 x_3 geq 64 334 56 yes rule 5\n7 x_1 geq 32000    x_3 geq 64 517 67  \n8 x_4  8 50 312  \n9 x_4 geq 8 312 50 yes rule 8\n10 x_5  50 335 58  \n11 x_5 geq 50 58 335 yes rule 10\n12 x_1 geq 32000    x_3  64 192 102 yes rule 1, 5, 7\n13 x_1  32000    x_4 geq 8 157 100  \n14 x_1 geq 32000    x_4  12 554 73  \n15 x_1 geq 32000    x_4  12 252 96 yes rule 1 and 14\n16 x_2 geq 8000    x_4 geq 12 586 76  \n17 x_2 geq 8000    x_4  12 236 94 yes rule 3 and 16","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"Compared to the example from the Supplementary PDF, the features are renamed such that 2 = MMAX, 2 = MMIN, 3 = CACH, 4 = CHMIN, and 5 = MYCT and one sign was flipped in rule 14 after email correspondence with Clément. From this set of rules, the algorithm should remove rule 2, 4, 6, 9, 11, 12, 15, and 17. This is because rule 2, 4, 6, 9, and 11 are the reverse of an earlier rule and because 12, 15, and 17 are linearly dependent. For the complex linearly dependent duplicates, remove the rule with the widest gap in the outputs. In the example above, rule 7 has a wider gap than rule 12, which implies that it has a larger CART-splitting criterion and a higher occurrence frequency.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"The implementation for this can be done by converting the training data to a feature space in which each rule becomes a binary feature indicating whether the data point satisfies the constraint or not. This is quite computationally intensive since there is a lot of duplication in the data and it doesn't guarantee that all cases of duplication will be found since some may not be in the training set. Luckily, D.W. on StackExchange (https://cs.stackexchange.com/questions/152803) has provided a solution, which I will repeat here. The idea is to remove each rule r when it is linearly dependent on the preceding rules.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"To do this, observe that a rule of the form A can only depend on rules A or A, and A    B can only depend on rules that use some combination of A, A, B, and/or B. This works by iteratively calculating the rank and seeing whether the rank increases.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"We can assume that we are limited to a set of rules where either A & B, A & !B, !A & B, !A & !B, A, !A, B, !B or True. This last case is not a valid rule in this algorithm, so that will not happen. Now, given A and B, we can create a binary matrix with a row for A & B, A & !B, !A & B, !A & !B. Next, generate one column containing trues and one column for each rule in rules. In each column, answer whether the rule holds for some point that satisifies the conditional. Next, calculate the rank and see whether the rank increases when adding additional rules. If the rank increases, then the added rule was not linearly dependent and if the rank does not increase, then the added rule is linearly dependent with earlier added rules.","category":"page"},{"location":"implementation-overview/","page":"Implementation Overview","title":"Implementation Overview","text":"Finally, the weights are determined by converting the training data to a rule space. According to Clément Bénard, the best way is to fit a regression model on a dataset where each rule is a binary feature. Furthermore, the weights can be stabilized by using an L2-penalty (ridge); this helps because the rules are quite strongly correlated. He also advised against the L1-penalty (lasso) as it would introduce additional sparsity and then instability of the rule selection since lasso is unstable with correlated features. Finally, the weights are constrained to all be positive since this eases interpretability.","category":"page"}]
}
